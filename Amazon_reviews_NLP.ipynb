{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNfkOL6KrJ3s/0biC3Bmwf4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jubacochran/NLP/blob/main/Amazon_reviews_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Introduction\n",
        "\n",
        "In this project, I developed a Neural Language Processing (NLP) model using the Keras deep learning library in Python. My primary objectives were:\n",
        "\n",
        "To practice an end-to-end NLP pipeline, including data preprocessing, tokenization, and training deep learning models.\n",
        "To experiment with different activation functions (Sigmoid, Tanh, and ReLU) and evaluate their impact on the model’s performance.\n",
        "To apply a chosen optimization technique (e.g., Adam or SGD) and discuss its influence on training convergence.\n",
        "To analyze the results, visualize performance metrics, and gain insights into the best configuration.\n",
        "2. Dataset\n",
        "\n",
        "Dataset Source: Amazon Reviews dataset from Kaggle\n",
        "\n",
        "I selected the Amazon Reviews dataset, which contains product reviews along with their sentiment polarity (positive or negative). The dataset is split into training and test sets and includes a textual field (text) and a polarity field.\n",
        "\n",
        "3. Data Preprocessing\n",
        "\n",
        "Loading Data:\n",
        "I downloaded the dataset from Kaggle and loaded it into Pandas dataframes. Both the training and testing data included columns polarity, title, and text.\n",
        "\n",
        "Cleaning and Formatting: I dropped the title field, focusing solely on text for sentiment classification. Polarity values were initially {1 (negative), 2 (positive)}, which I adjusted to {0 (negative), 1 (positive)} for a binary classification setup.\n",
        "\n",
        "Sampling: Due to the large dataset size, I sampled a small fraction (5%) of the training data to speed up experimentation while maintaining class balance.\n",
        "\n",
        "Splitting Data: I split the sampled training data into training, validation, and test sets using train_test_split. I ensured stratification so that the class distribution remained consistent.\n",
        "\n",
        "Tokenization & Vocabulary: I built a vocabulary from the top frequent words in the training set and used WordPiece tokenization to handle out-of-vocabulary tokens. I included special tokens ([PAD], [UNK], [CLS], [SEP], [MASK]) to align with transformer-based approaches.\n",
        "\n",
        "Padding & Sequences: After determining a maximum sequence length based on the 90th percentile of text length, I padded or truncated all reviews to this fixed length. This ensured uniform input shapes for the model.\n",
        "\n",
        "4. Model Design\n",
        "\n",
        "I experimented with two main architectures:\n",
        "\n",
        "Baseline Convolutional Model:\n",
        "\n",
        "Architecture:\n",
        "Embedding Layer: Converts token IDs into dense embeddings.\n",
        "Conv1D Layer: Captures local n-gram features with a kernel size of 5.\n",
        "Global Max Pooling: Reduces the sequence dimension by taking the maximum feature map across time steps.\n",
        "Fully Connected Layer (Dense): A dense layer with 128 units and a chosen activation function.\n",
        "Dropout: Regularization to prevent overfitting.\n",
        "Output Layer: A single neuron with Sigmoid activation for binary classification.\n",
        "This model meets the requirement of having at least three hidden layers (Conv1D, Dense, and another Dense before the output).\n",
        "\n",
        "Transformer-based Model:\n",
        "\n",
        "Architecture:\n",
        "Token & Position Embedding: Combines learned word embeddings and positional embeddings.\n",
        "Transformer Block: Utilizes Multi-Head Attention and a Feed-Forward Network. This block helps the model attend to various parts of the input sequence.\n",
        "Global Average Pooling: Summarizes sequence-level features.\n",
        "Fully Connected Layers: Dense layers followed by dropout.\n",
        "Output Layer: A single neuron with Sigmoid activation.\n",
        "I tested various hyperparameters for the transformer block (number of heads, feed-forward dimension) using Weights & Biases (W&B) sweeps.\n",
        "\n",
        "5. Activation Functions Experimentation\n",
        "\n",
        "I explored different activation functions in the Dense layers:\n",
        "\n",
        "Sigmoid:\n",
        "\n",
        "Commonly used in output layers for binary classification.\n",
        "In hidden layers, it often leads to vanishing gradients due to saturation.\n",
        "Observation: Models using Sigmoid in hidden layers trained slower and often got stuck in local minima, resulting in lower validation accuracy.\n",
        "Tanh:\n",
        "\n",
        "Similar to Sigmoid but outputs values in [-1, 1]. This can provide a stronger gradient signal.\n",
        "Tanh outperformed Sigmoid slightly but still sometimes suffered from saturation issues, especially in deeper networks.\n",
        "ReLU (Rectified Linear Unit):\n",
        "\n",
        "ReLU typically leads to faster training convergence because it avoids saturation in positive ranges.\n",
        "In my experiments, ReLU provided the best validation accuracy and the most stable training dynamics.\n",
        "Findings:\n",
        "ReLU consistently outperformed Sigmoid and Tanh for the hidden layers in terms of training speed and accuracy. However, for the output layer, Sigmoid remained the appropriate choice because it maps outputs to [0,1], making it well-suited for probability interpretation in binary classification.\n",
        "\n",
        "6. Optimization Technique\n",
        "\n",
        "I used the Adam optimizer, a popular variant of gradient-based optimization that adapts the learning rate for each parameter. Adam typically converges faster and more reliably than standard SGD, making it ideal for NLP tasks with large vocabularies.\n",
        "\n",
        "Influence on Training:\n",
        "Adam’s adaptive learning rate helped me achieve quick and stable convergence. With SGD, initial experiments required careful learning rate tuning, whereas with Adam, I got stable results without extensive manual adjustments.\n",
        "7. Training Process and Hyperparameter Sweeps\n",
        "\n",
        "Training Setup:\n",
        "\n",
        "I trained for 5 to 50 epochs, depending on the model complexity.\n",
        "Batch sizes: experimented with 32, 64, 128.\n",
        "Early Stopping: Used a patience of a few epochs to revert to the best model weights.\n",
        "W&B Sweeps: I performed hyperparameter sweeps over:\n",
        "\n",
        "Number of attention heads\n",
        "Feed-forward network dimension\n",
        "Learning rate\n",
        "Batch size\n",
        "Epochs\n",
        "Sweeps helped identify configurations that slightly improved validation accuracy. Generally, balancing model complexity with regularization was key to avoiding overfitting.\n",
        "\n",
        "8. Evaluation\n",
        "\n",
        "Metrics:\n",
        "I used accuracy as the primary metric and tracked validation accuracy and loss across epochs. This helped ensure that I was not overfitting and that the models were improving over time.\n",
        "\n",
        "Baseline Conv Model Performance: The baseline model achieved around ~88-89% validation accuracy after a few epochs of training. Using ReLU in the hidden layers provided more stable improvements.\n",
        "\n",
        "Transformer-Based Model Performance: The transformer-based model also reached ~88-89% validation accuracy under the constraints of my small training subset. While transformers have the potential to outperform simpler architectures with enough data and tuning, I was limited by the reduced dataset fraction.\n",
        "\n",
        "Impact of Activation Functions:\n",
        "\n",
        "Sigmoid in hidden layers: Led to slower convergence and slightly lower accuracy.\n",
        "Tanh in hidden layers: Better than Sigmoid but still lagged behind ReLU.\n",
        "ReLU in hidden layers: Provided the best performance and stability.\n",
        "9. Visualizations\n",
        "\n",
        "Accuracy and Loss Curves:\n",
        "Plots of training and validation accuracy vs. epochs and loss vs. epochs showed that models with ReLU converged more smoothly and avoided early plateaus.\n",
        "\n",
        "Confusion Matrix:\n",
        "On the test set, the confusion matrix indicated that the model correctly classified most samples. Misclassifications generally occurred with ambiguous reviews.\n",
        "\n",
        "10. Conclusion and Findings\n",
        "\n",
        "Key Insights:\n",
        "Activation Functions: Using ReLU in hidden layers yielded superior performance compared to Sigmoid or Tanh.\n",
        "Optimizer: Adam proved effective and convenient, requiring minimal manual tuning.\n",
        "Model Architecture: Both the baseline CNN-based model and the transformer-based model achieved similar results given my small training subset. With more data and compute, the transformer might have shown a more substantial improvement.\n",
        "Future Work: I could further improve results by training on a larger portion of the data, increasing epochs, or fine-tuning a pre-trained language model like BERT.\n"
      ],
      "metadata": {
        "id": "e9OJ0gqOD9Uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras-hub"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BvYtrTDLvSUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77bc323d-d4b3-49b3-b982-c06aef04f8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-hub\n",
            "  Downloading keras_hub-0.18.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-hub) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-hub) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-hub) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-hub) (2024.11.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-hub) (13.9.4)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-hub) (0.3.5)\n",
            "Collecting tensorflow-text (from keras-hub)\n",
            "  Downloading tensorflow_text-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-hub) (4.67.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub) (4.12.2)\n",
            "Collecting tensorflow<2.19,>=2.18.0 (from tensorflow-text->keras-hub)\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (1.68.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.5.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub) (2024.12.14)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.45.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.13.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.0.2)\n",
            "Downloading keras_hub-0.18.1-py3-none-any.whl (691 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.2/691.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard, tensorflow, tensorflow-text, keras-hub\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-hub-0.18.1 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-text-2.18.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras-cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RZciWV9CveWH",
        "outputId": "4702d5ae-15f3-4958-e946-7dd5b92da8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-cv\n",
            "  Downloading keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-cv) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-cv) (2024.11.6)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras-cv) (4.9.7)\n",
            "Collecting keras-core (from keras-cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-cv) (0.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-cv) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-cv) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (3.12.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (8.1.7)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (4.25.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (17.0.0)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.13.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (2.5.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.17.0)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (0.5.1)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv) (1.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv) (6.4.5)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv) (4.12.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (2024.12.14)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras-cv) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-cv) (2.18.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->keras-cv) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv) (1.66.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-cv) (0.1.2)\n",
            "Downloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-core, keras-cv\n",
            "Successfully installed keras-core-0.1.7 keras-cv-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from wandb.integration.keras import WandbMetricsLogger,WandbCallback,WandbEvalCallback,WandbModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import math\n",
        "from tensorflow.keras import ops\n",
        "from keras_hub.tokenizers import WordPieceTokenizer\n",
        "from collections import Counter\n",
        "import tensorflow_text as text\n"
      ],
      "metadata": {
        "id": "Xx3hgj0XBjDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "qvXJurqHhG4B",
        "outputId": "5311173a-b52e-4eda-db93-e99f15343cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThuUod0wBORn",
        "outputId": "02adf451-1ee0-4564-c13e-59ba9851ea55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kritanjalijain/amazon-reviews?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.29G/1.29G [00:12<00:00, 114MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/kritanjalijain/amazon-reviews/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kritanjalijain/amazon-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_data = pd.read_csv(path + \"/train.csv\", header=None, names =['polarity','title','text'])\n",
        "testing_data = pd.read_csv(path + \"/test.csv\", header=None, names =['polarity','title','text'])"
      ],
      "metadata": {
        "id": "AGSGqmaKBeWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.drop('title', axis=1, inplace=True)\n",
        "testing_data.drop('title', axis=1, inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "_zu4t2jMbGHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_fraction = 0.1\n",
        "training_data_sampled = training_data.groupby('polarity', group_keys=False).apply(lambda x: x.sample(frac=train_sample_fraction, random_state=42))\n",
        "\n",
        "print(f\"Sampled Data Shape: {training_data_sampled.shape}\")\n",
        "print(\"\\nSampled Class Distribution:\\n\", training_data_sampled['polarity'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNIm8aJJLQsJ",
        "outputId": "6eaa9d73-15ad-4fbb-e294-8368070886bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled Data Shape: (360000, 2)\n",
            "\n",
            "Sampled Class Distribution:\n",
            " polarity\n",
            "1    180000\n",
            "2    180000\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1adbf381b31f>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  training_data_sampled = training_data.groupby('polarity', group_keys=False).apply(lambda x: x.sample(frac=train_sample_fraction, random_state=42))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_char_length = training_data_sampled['text'].str.len().max()\n",
        "min_char_length = training_data_sampled['text'].str.len().min()\n",
        "print(max_char_length)\n",
        "print(min_char_length)\n",
        "\n",
        "p90=int(np.percentile(training_data_sampled['text'].str.len(),90))\n",
        "print(p90)\n",
        "print(type(p90))\n",
        "int(p90)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn1MPsFS4ymU",
        "outputId": "f6b1a1d8-3f2d-4ac7-a70b-4f9c6636a9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1008\n",
            "25\n",
            "769\n",
            "<class 'int'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "769"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = training_data_sampled.drop('polarity', axis=1)\n",
        "y = training_data_sampled['polarity']"
      ],
      "metadata": {
        "id": "W3Mruq3SMN2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=42)"
      ],
      "metadata": {
        "id": "Q6f-dhUJLl7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining Data Shape:\", X_train.shape)\n",
        "print(\"\\nValidation Data Shape:\", X_val.shape)\n",
        "print(\"\\nTest Data Shape:\", X_test.shape)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_val.value_counts())\n",
        "print(y_test.value_counts())\n",
        "print(y_train.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTsA_wmfMxxR",
        "outputId": "2e8a100b-80a4-4af0-c885-97a11cec5bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Data Shape: (216000, 1)\n",
            "\n",
            "Validation Data Shape: (72000, 1)\n",
            "\n",
            "Test Data Shape: (72000, 1)\n",
            "polarity\n",
            "2    108000\n",
            "1    108000\n",
            "Name: count, dtype: int64\n",
            "polarity\n",
            "1    36000\n",
            "2    36000\n",
            "Name: count, dtype: int64\n",
            "polarity\n",
            "1    36000\n",
            "2    36000\n",
            "Name: count, dtype: int64\n",
            "[2 2 1 ... 1 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I need to fix labels to 0 or 1. Right now they are 2(positive) and 1(negative)\n",
        "\n",
        "y_train = np.array(y_train) - 1\n",
        "y_val = np.array(y_val) - 1\n",
        "y_test = np.array(y_test) - 1\n",
        "\n",
        "# Verify the label conversion\n",
        "print(\"Unique values in y_train:\", np.unique(y_train))\n",
        "print(\"Unique values in y_val:\", np.unique(y_val))\n",
        "print(\"Unique values in y_test:\", np.unique(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSy5nHJsJWAr",
        "outputId": "35eed21f-6b81-4aa7-daff-bcdfabb7fb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in y_train: [0 1]\n",
            "Unique values in y_val: [0 1]\n",
            "Unique values in y_test: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_text = X_train['text'].to_list()\n",
        "\n",
        "# Tokenize the words and create a vocabulary\n",
        "all_text = ' '.join(X_train_text)\n",
        "all_tokens = all_text.split()\n",
        "\n",
        "# Count the most frequent tokens\n",
        "token_counts = Counter(all_tokens)\n",
        "vocab_list = [word for word, count in token_counts.most_common(30000)]\n",
        "\n",
        "# Add special tokens\n",
        "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "vocab_list = special_tokens + vocab_list\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab_list)}\")\n",
        "print(f\"Sample vocabulary: {vocab_list[:10]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0_ErffH8xvk",
        "outputId": "e3459ef2-83ed-4e2d-a57c-089fbba6248a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 30005\n",
            "Sample vocabulary: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', 'the', 'and', 'I', 'to', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vocab_size = 10000\n",
        "#embedding_dim = int(math.sqrt(vocab_size))\n",
        "#print(f\"Embedding Dimension: {embedding_dim}\")\n",
        "#tokenizer = Tokenizer(num_words=None, oov_token='<OOV>',lower=True)\n",
        "#tokenizer.fit_on_texts(X_train['text'])\n",
        "\n",
        "tokenizer = WordPieceTokenizer(\n",
        "    vocabulary = vocab_list,\n",
        "    sequence_length = p90,\n",
        "    lowercase = True,\n",
        "    oov_token = \"[UNK]\",\n",
        "    special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"],\n",
        "    special_tokens_in_strings = True,\n",
        "    dtype=\"int32\"\n",
        ")"
      ],
      "metadata": {
        "id": "2JxZQw8Fz5lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokens = tokenizer.tokenize(X_train['text'].to_list())\n",
        "X_val_tokens = tokenizer.tokenize(X_val['text'].to_list())\n",
        "X_test_tokens = tokenizer.tokenize(X_test['text'].to_list())\n",
        "\n",
        "\n",
        "print(\"Sample Tokenized X_train:\", X_train_tokens[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdUHSdk29eqN",
        "outputId": "ef93a365-ab77-4b73-99ef-ddc1ccb6dcf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Tokenized X_train: tf.Tensor(\n",
            "[[  5 278  10 ...   0   0   0]\n",
            " [ 99  21 142 ...   0   0   0]\n",
            " [ 83 343  83 ...   0   0   0]], shape=(3, 769), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.get_vocabulary()\n",
        "print(type(X_train_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k9ZoD6-wOqj",
        "outputId": "651c269a-86ca-4ce2-efc8-f81572117682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab_list)  # This comes from your vocabulary\n",
        "print(vocab_size)\n",
        "embedding_dim = int(math.sqrt(vocab_size))  # Size of the embedding vector\n",
        "print(embedding_dim)\n",
        "sequence_length = p90"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3SYba6FP0zo",
        "outputId": "d92d9ab3-7e0d-4019-ed44-2a6119282672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30005\n",
            "173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length),  # Embedding layer\n",
        "    layers.Conv1D(128, 5, activation='relu'),  # 1D convolutional layer\n",
        "    layers.GlobalMaxPooling1D(),  # Global max pooling\n",
        "    layers.Dense(128, activation='relu'),  # Fully connected layer\n",
        "    layers.Dropout(0.5),  # Dropout for regularization\n",
        "    layers.Dense(1, activation='sigmoid')  # Final binary classification layer (binary classification)\n",
        "])\n",
        "# Build the model to define the input shape\n",
        "model.build(input_shape=(None, sequence_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBGTJcV_H4lV",
        "outputId": "979a6ad6-1b8b-43a9-8065-ca506cfc9e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Initialize a new W&B run\n",
        "wandb.init(project=\"transformer-sweep\", group=\"baseline-model\", config={\"baseline\": 2})\n",
        "\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(\n",
        "    X_train_tokens,\n",
        "    y_train,\n",
        "    epochs=5,\n",
        "    validation_data=(X_val_tokens, y_val),\n",
        "    batch_size=64,\n",
        "    callbacks=[WandbMetricsLogger(),WandbModelCheckpoint(\"/content/sample_data/models/base_model.keras\")]\n",
        ")\n",
        "test_results = model.evaluate(X_test_tokens, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_results[1]*100:.2f}%\")\n",
        "wandb.log({\"test_accuracy\": test_results[1]})\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1pQ0Ex6xH4gK",
        "outputId": "bc9955d9-bce5-4eb7-c9ef-01f5a4191583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m769\u001b[0m, \u001b[38;5;34m173\u001b[0m)            │       \u001b[38;5;34m5,190,865\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m765\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m110,848\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,190,865</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">765</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">110,848</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,318,354\u001b[0m (20.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,318,354</span> (20.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,318,354\u001b[0m (20.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,318,354</span> (20.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjubacochran\u001b[0m (\u001b[33mjubacochran-booking-com\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241219_234252-rhfz96k1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/rhfz96k1' target=\"_blank\">lunar-monkey-49</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/rhfz96k1' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/rhfz96k1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8394 - loss: 0.3447 - val_accuracy: 0.9116 - val_loss: 0.2197\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9383 - loss: 0.1677 - val_accuracy: 0.9142 - val_loss: 0.2193\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9657 - loss: 0.0988 - val_accuracy: 0.9093 - val_loss: 0.2654\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0516 - val_accuracy: 0.9060 - val_loss: 0.3233\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9897 - loss: 0.0299 - val_accuracy: 0.8947 - val_loss: 0.4032\n",
            "Test Accuracy: 89.69%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▄▆▇█</td></tr><tr><td>epoch/epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▃▂▁</td></tr><tr><td>epoch/val_accuracy</td><td>▇█▆▅▁</td></tr><tr><td>epoch/val_loss</td><td>▁▁▃▅█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.98711</td></tr><tr><td>epoch/epoch</td><td>4</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.03734</td></tr><tr><td>epoch/val_accuracy</td><td>0.89471</td></tr><tr><td>epoch/val_loss</td><td>0.40318</td></tr><tr><td>test_accuracy</td><td>0.89688</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lunar-monkey-49</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/rhfz96k1' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/rhfz96k1</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241219_234252-rhfz96k1/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feedForward_dim = 64\n",
        "num_heads = 2\n",
        "maxlen = p90\n",
        "embedding_dim = 25\n",
        "\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "KK5ZiYdsmK8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d4e207-f733-4db2-fc62-0bee081a8b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets try and improve this obviously poor model. I'll use Transformer blocks and attention heads to help\n",
        "\n",
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "  def __init__(self, embedding_dim, num_heads, feedForward_dim, rate=0.1):\n",
        "    super().__init__()\n",
        "    self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n",
        "    self.feedForwardNetwork = keras.Sequential(\n",
        "        [layers.Dense(feedForward_dim, activation=\"relu\"), layers.Dense(embedding_dim),]\n",
        "    )\n",
        "    self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.dropout1 = layers.Dropout(rate)\n",
        "    self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    attn_output = self.att(inputs, inputs)\n",
        "    attn_output = self.dropout1(attn_output)\n",
        "    LmHead = self.layernorm1(inputs + attn_output)\n",
        "    feedForwardNetwork_output = self.feedForwardNetwork(LmHead)\n",
        "    feedForwardNetwork_output = self.dropout2(feedForwardNetwork_output)\n",
        "    return self.layernorm2(LmHead + feedForwardNetwork_output)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LTdaaEt8H4Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Embbedding layer\n",
        "\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "  def __init__(self, maxlen, vocab_size, embedding_dim):\n",
        "    super().__init__()\n",
        "    self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "    self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embedding_dim)\n",
        "\n",
        "  def call(self, x):\n",
        "    maxlen = ops.shape(x)[-1]\n",
        "    positions = ops.arange(start=0, stop=maxlen, step=1)\n",
        "    positions = self.pos_emb(positions)\n",
        "    x = self.token_emb(x)\n",
        "    return x + positions"
      ],
      "metadata": {
        "id": "aqAnP309k7uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(p90,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embedding_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embedding_dim, num_heads, feedForward_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(15, activation='relu')(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "model_transformer = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model_transformer.summary()"
      ],
      "metadata": {
        "id": "f3VZ33JvmLcI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "46503ca4-a909-4da9-d4a9-664a00b098ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m769\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m769\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m769,350\u001b[0m │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block (\u001b[38;5;33mTransformerBlock\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m769\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │           \u001b[38;5;34m8,564\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m16\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">769,350</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,564</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m778,320\u001b[0m (2.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">778,320</span> (2.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m778,320\u001b[0m (2.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">778,320</span> (2.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_transformer.compile(optimizer = 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "wandb.init(config={\"transformer\": 2}, project = 'production_model')\n",
        "history = model_transformer.fit(X_train_tokens,y_train,epochs=50,\n",
        "                                validation_data=(X_val_tokens,y_val),\n",
        "                                batch_size=64,\n",
        "                                callbacks=[early_stopping,WandbMetricsLogger(),WandbModelCheckpoint(\"/content/sample_data/models/transformer_model_transformer.keras\")])\n",
        "\n",
        "test_results = model_transformer.evaluate(X_test_tokens, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_results[1]*100:.2f}%\")\n",
        "wandb.log({\"test_accuracy\": test_results[1]})\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "o8zxdj6gmLlM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "c78371d8-466f-4173-f121-1ef13bb13093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241219_234422-66vvbk9v</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/production_model/runs/66vvbk9v' target=\"_blank\">dutiful-disco-4</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/production_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/production_model' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/production_model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/production_model/runs/66vvbk9v' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/production_model/runs/66vvbk9v</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - accuracy: 0.4997 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 2/50\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - accuracy: 0.5305 - loss: 0.6666 - val_accuracy: 0.8674 - val_loss: 0.3153\n",
            "Epoch 3/50\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.8810 - loss: 0.2935 - val_accuracy: 0.8787 - val_loss: 0.2878\n",
            "Epoch 4/50\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - accuracy: 0.8910 - loss: 0.2660 - val_accuracy: 0.8800 - val_loss: 0.2859\n",
            "Epoch 5/50\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - accuracy: 0.8962 - loss: 0.2523 - val_accuracy: 0.8780 - val_loss: 0.2873\n",
            "Epoch 6/50\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - accuracy: 0.8996 - loss: 0.2392 - val_accuracy: 0.8790 - val_loss: 0.3009\n",
            "Epoch 7/50\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - accuracy: 0.9012 - loss: 0.2328 - val_accuracy: 0.8775 - val_loss: 0.3046\n",
            "Test Accuracy: 88.12%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▃█████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▂▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁██████</td></tr><tr><td>epoch/val_loss</td><td>█▂▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.89922</td></tr><tr><td>epoch/epoch</td><td>6</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.23734</td></tr><tr><td>epoch/val_accuracy</td><td>0.87749</td></tr><tr><td>epoch/val_loss</td><td>0.30464</td></tr><tr><td>test_accuracy</td><td>0.88118</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dutiful-disco-4</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/production_model/runs/66vvbk9v' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/production_model/runs/66vvbk9v</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/production_model' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/production_model</a><br>Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241219_234422-66vvbk9v/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up W&B Hypertuning\n",
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {'name': 'val_loss', 'goal': 'minimize'},\n",
        "    'parameters': {\n",
        "        'num_heads': {'values': [2, 4, 8]},\n",
        "        'feedForward_dim': {'values': [64, 128, 256]},\n",
        "        'batch_size': {'values': [32, 64, 128]},\n",
        "        'epochs': {'values': [10, 20, 30]},\n",
        "        'learning_rate':{'values': [1e-6, 2e-6, 5e-6, 1e-5, 2e-5, 3e-5, 5e-5, 1e-4]}\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "B7OE4oYOWfHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hypertuning_model(config=None):\n",
        "    # Extract the hyperparameters from the W&B config\n",
        "    num_heads = config['num_heads']\n",
        "    feedForward_dim = config['feedForward_dim']\n",
        "    batch_size = config['batch_size']\n",
        "    epochs = config['epochs']\n",
        "\n",
        "    inputs = layers.Input(shape=(maxlen,))\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embedding_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block = TransformerBlock(embedding_dim, num_heads, feedForward_dim)\n",
        "    x = transformer_block(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(20, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model_hypertuning = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
        "    model_hypertuning.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "SrvkvzInWffX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sweep_train(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "        model = hypertuning_model(config)\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train_tokens,\n",
        "            y_train,\n",
        "            epochs=config.epochs,\n",
        "            validation_data=(X_val_tokens, y_val),\n",
        "            batch_size=config.batch_size,\n",
        "            callbacks=[\n",
        "                wandb.keras.WandbMetricsLogger(),\n",
        "                wandb.keras.WandbModelCheckpoint(\"/content/sample_data/models/transformer_model_hyperparameter.keras\")\n",
        "]\n",
        "        )\n",
        "\n",
        "        test_results = model.evaluate(X_test_tokens, y_test, verbose=0)\n",
        "        print(f\"Test Accuracy: {test_results[1]*100:.2f}%\")\n",
        "        wandb.log({\"test_accuracy\": test_results[1]})\n",
        "        wandb.finish()"
      ],
      "metadata": {
        "id": "EB0UHgHVWfnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize the sweep\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project=\"transformer-sweep\")\n",
        "\n",
        "# 2. Run the sweep agent (this triggers multiple hyperparameter runs)\n",
        "wandb.agent(sweep_id, function=sweep_train, count=10)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "moeJ6WQxYLHY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "557a59a6-cb49-4f85-f76a-e86511456d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: ulyniuk5\n",
            "Sweep URL: https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3j3vkfb4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241219_234826-3j3vkfb4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/3j3vkfb4' target=\"_blank\">scarlet-sweep-1</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/3j3vkfb4' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/3j3vkfb4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.0231 - val_accuracy: 0.9032 - val_loss: 0.4193\n",
            "Epoch 2/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 0.0182 - val_accuracy: 0.8969 - val_loss: 0.5310\n",
            "Epoch 3/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0148 - val_accuracy: 0.8988 - val_loss: 0.5451\n",
            "Epoch 4/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 0.0136 - val_accuracy: 0.9014 - val_loss: 0.5420\n",
            "Epoch 5/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0118 - val_accuracy: 0.8971 - val_loss: 0.5539\n",
            "Epoch 6/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0100 - val_accuracy: 0.9013 - val_loss: 0.5686\n",
            "Epoch 7/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0093 - val_accuracy: 0.9017 - val_loss: 0.6055\n",
            "Epoch 8/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0082 - val_accuracy: 0.9014 - val_loss: 0.6644\n",
            "Epoch 9/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.8999 - val_loss: 0.7451\n",
            "Epoch 10/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0072 - val_accuracy: 0.9016 - val_loss: 0.6462\n",
            "Test Accuracy: 90.13%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>█▁▃▆▁▆▆▆▄▆</td></tr><tr><td>epoch/val_loss</td><td>▁▃▄▄▄▄▅▆█▆</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.99715</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00893</td></tr><tr><td>epoch/val_accuracy</td><td>0.9016</td></tr><tr><td>epoch/val_loss</td><td>0.64618</td></tr><tr><td>test_accuracy</td><td>0.90133</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">scarlet-sweep-1</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/3j3vkfb4' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/3j3vkfb4</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241219_234826-3j3vkfb4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 237zrz7b with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241219_235112-237zrz7b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/237zrz7b' target=\"_blank\">classic-sweep-2</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/237zrz7b' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/237zrz7b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0145 - val_accuracy: 0.8985 - val_loss: 0.6509\n",
            "Epoch 2/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.9008 - val_loss: 0.7081\n",
            "Epoch 3/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0103 - val_accuracy: 0.8997 - val_loss: 0.6386\n",
            "Epoch 4/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0095 - val_accuracy: 0.8956 - val_loss: 0.5926\n",
            "Epoch 5/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0078 - val_accuracy: 0.8988 - val_loss: 0.7852\n",
            "Epoch 6/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.9002 - val_loss: 0.6770\n",
            "Epoch 7/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.8888 - val_loss: 0.9165\n",
            "Epoch 8/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0066 - val_accuracy: 0.8978 - val_loss: 0.9729\n",
            "Epoch 9/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.8979 - val_loss: 0.8160\n",
            "Epoch 10/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.8975 - val_loss: 0.9430\n",
            "Epoch 11/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0058 - val_accuracy: 0.8990 - val_loss: 0.7963\n",
            "Epoch 12/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.8981 - val_loss: 0.9643\n",
            "Epoch 13/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.8978 - val_loss: 1.0676\n",
            "Epoch 14/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 0.8960 - val_loss: 0.8550\n",
            "Epoch 15/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.8887 - val_loss: 1.1486\n",
            "Epoch 16/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.8986 - val_loss: 0.8525\n",
            "Epoch 17/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.8929 - val_loss: 1.0463\n",
            "Epoch 18/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 0.8973 - val_loss: 1.0653\n",
            "Epoch 19/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.8957 - val_loss: 1.0259\n",
            "Epoch 20/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.8947 - val_loss: 1.2304\n",
            "Epoch 21/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.8976 - val_loss: 0.9624\n",
            "Epoch 22/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.8899 - val_loss: 1.4575\n",
            "Epoch 23/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.8974 - val_loss: 1.1067\n",
            "Epoch 24/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.8973 - val_loss: 1.5244\n",
            "Epoch 25/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.8984 - val_loss: 1.1920\n",
            "Epoch 26/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.8902 - val_loss: 1.4621\n",
            "Epoch 27/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.8985 - val_loss: 1.6191\n",
            "Epoch 28/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.8954 - val_loss: 1.2753\n",
            "Epoch 29/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.8962 - val_loss: 1.4697\n",
            "Epoch 30/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.8969 - val_loss: 1.3517\n",
            "Test Accuracy: 89.91%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▃▃▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▅▄▄▃▃▃▃▃▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▇█▇▅▇█▁▆▆▆▇▆▆▅▁▇▃▆▅▄▆▂▆▆▇▂▇▅▅▆</td></tr><tr><td>epoch/val_loss</td><td>▁▂▁▁▂▂▃▄▃▃▂▄▄▃▅▃▄▄▄▅▄▇▅▇▅▇█▆▇▆</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.99891</td></tr><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00487</td></tr><tr><td>epoch/val_accuracy</td><td>0.89686</td></tr><tr><td>epoch/val_loss</td><td>1.35175</td></tr><tr><td>test_accuracy</td><td>0.8991</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">classic-sweep-2</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/237zrz7b' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/237zrz7b</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 60 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241219_235112-237zrz7b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e6c89lyy with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_000331-e6c89lyy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/e6c89lyy' target=\"_blank\">dandy-sweep-3</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/e6c89lyy' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/e6c89lyy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.8946 - val_loss: 1.4268\n",
            "Epoch 2/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.8958 - val_loss: 1.5216\n",
            "Epoch 3/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.8983 - val_loss: 1.6082\n",
            "Epoch 4/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.8955 - val_loss: 1.7578\n",
            "Epoch 5/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 8.7850e-04 - val_accuracy: 0.8970 - val_loss: 1.6113\n",
            "Epoch 6/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.8971 - val_loss: 1.9423\n",
            "Epoch 7/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.8951 - val_loss: 1.9003\n",
            "Epoch 8/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.8941 - val_loss: 1.8658\n",
            "Epoch 9/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.8963 - val_loss: 1.6199\n",
            "Epoch 10/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 8.6287e-04 - val_accuracy: 0.8953 - val_loss: 1.9914\n",
            "Test Accuracy: 89.83%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▃▅▅█▄▄▇</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▅▃▆▆▂▄▁▄█▁</td></tr><tr><td>epoch/val_accuracy</td><td>▂▄█▃▆▆▃▁▅▃</td></tr><tr><td>epoch/val_loss</td><td>▁▂▃▅▃▇▇▆▃█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.99962</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00145</td></tr><tr><td>epoch/val_accuracy</td><td>0.89525</td></tr><tr><td>epoch/val_loss</td><td>1.99138</td></tr><tr><td>test_accuracy</td><td>0.89831</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dandy-sweep-3</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/e6c89lyy' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/e6c89lyy</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241220_000331-e6c89lyy/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ou90zpb6 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_000618-ou90zpb6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ou90zpb6' target=\"_blank\">lively-sweep-4</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ou90zpb6' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ou90zpb6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.8958 - val_loss: 2.0128\n",
            "Epoch 2/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.8957 - val_loss: 2.3812\n",
            "Epoch 3/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.8944 - val_loss: 2.3050\n",
            "Epoch 4/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.8960 - val_loss: 2.1603\n",
            "Epoch 5/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.8965 - val_loss: 2.0952\n",
            "Epoch 6/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.8966 - val_loss: 2.1026\n",
            "Epoch 7/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.8968 - val_loss: 2.1559\n",
            "Epoch 8/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.8964 - val_loss: 1.7156\n",
            "Epoch 9/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 9.2120e-04 - val_accuracy: 0.8959 - val_loss: 2.1617\n",
            "Epoch 10/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.8962 - val_loss: 2.4649\n",
            "Epoch 11/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.8977 - val_loss: 1.8727\n",
            "Epoch 12/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 8.0075e-04 - val_accuracy: 0.8956 - val_loss: 2.3845\n",
            "Epoch 13/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.8965 - val_loss: 1.9758\n",
            "Epoch 14/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.8958 - val_loss: 2.6046\n",
            "Epoch 15/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.8932 - val_loss: 2.7039\n",
            "Epoch 16/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.8974 - val_loss: 2.5191\n",
            "Epoch 17/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.8961 - val_loss: 1.9673\n",
            "Epoch 18/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.8954 - val_loss: 2.1699\n",
            "Epoch 19/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.8924 - val_loss: 2.3266\n",
            "Epoch 20/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.8940 - val_loss: 2.5391\n",
            "Epoch 21/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.8964 - val_loss: 2.9676\n",
            "Epoch 22/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.8941 - val_loss: 2.1252\n",
            "Epoch 23/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.8955 - val_loss: 2.6791\n",
            "Epoch 24/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.8949 - val_loss: 2.0210\n",
            "Epoch 25/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.8956 - val_loss: 2.2231\n",
            "Epoch 26/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.8955 - val_loss: 2.4532\n",
            "Epoch 27/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.8932 - val_loss: 3.0744\n",
            "Epoch 28/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.8929 - val_loss: 2.9467\n",
            "Epoch 29/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.8950 - val_loss: 2.5077\n",
            "Epoch 30/30\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 8.7847e-04 - val_accuracy: 0.8965 - val_loss: 3.0808\n",
            "Test Accuracy: 89.88%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▃▇▇▅▆▆▆▇█▅▁▇▅▇█▆▃▆▆▇▅▇▇▇▅▆▆▇▅█</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▆▂▃▃▃▄█▄▂▃█▁▅▂▁▃▇▇▂▁▃▄▄▄▄▂▅▂▇▃</td></tr><tr><td>epoch/val_accuracy</td><td>▆▅▄▆▆▇▇▆▆▆█▅▆▆▂█▆▅▁▃▆▃▅▄▅▅▂▂▄▆</td></tr><tr><td>epoch/val_loss</td><td>▃▄▄▃▃▃▃▁▃▅▂▄▂▆▆▅▂▃▄▅▇▃▆▃▄▅█▇▅█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.99963</td></tr><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00174</td></tr><tr><td>epoch/val_accuracy</td><td>0.89654</td></tr><tr><td>epoch/val_loss</td><td>3.08078</td></tr><tr><td>test_accuracy</td><td>0.89875</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lively-sweep-4</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ou90zpb6' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ou90zpb6</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 60 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241220_000618-ou90zpb6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9r0s4sp0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_001424-9r0s4sp0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/9r0s4sp0' target=\"_blank\">whole-sweep-5</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/9r0s4sp0' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/9r0s4sp0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 0.8926 - val_loss: 2.6517\n",
            "Epoch 2/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.8940 - val_loss: 2.3736\n",
            "Epoch 3/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.8955 - val_loss: 2.6897\n",
            "Epoch 4/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.8934 - val_loss: 3.0390\n",
            "Epoch 5/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.8939 - val_loss: 2.3609\n",
            "Epoch 6/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.8954 - val_loss: 2.6185\n",
            "Epoch 7/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.8962 - val_loss: 2.4959\n",
            "Epoch 8/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.8936 - val_loss: 2.4713\n",
            "Epoch 9/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.8946 - val_loss: 2.1254\n",
            "Epoch 10/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.8936 - val_loss: 2.7625\n",
            "Test Accuracy: 89.78%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▂▃▃▄▃▄▁█▃▄</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▅▂▃▅█▃▅▁█▂</td></tr><tr><td>epoch/val_accuracy</td><td>▁▄▇▃▄▇█▃▅▃</td></tr><tr><td>epoch/val_loss</td><td>▅▃▅█▃▅▄▄▁▆</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.99926</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00297</td></tr><tr><td>epoch/val_accuracy</td><td>0.89356</td></tr><tr><td>epoch/val_loss</td><td>2.76251</td></tr><tr><td>test_accuracy</td><td>0.89775</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">whole-sweep-5</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/9r0s4sp0' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/9r0s4sp0</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241220_001424-9r0s4sp0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ir4nddyu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_001842-ir4nddyu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ir4nddyu' target=\"_blank\">chocolate-sweep-6</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ir4nddyu' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ir4nddyu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0041 - val_accuracy: 0.8939 - val_loss: 2.4343\n",
            "Epoch 2/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.8888 - val_loss: 3.0222\n",
            "Epoch 3/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.8953 - val_loss: 2.5958\n",
            "Epoch 4/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.8947 - val_loss: 3.2179\n",
            "Epoch 5/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.8941 - val_loss: 2.6436\n",
            "Epoch 6/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.8939 - val_loss: 2.5748\n",
            "Epoch 7/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.8946 - val_loss: 2.8467\n",
            "Epoch 8/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.8972 - val_loss: 3.1408\n",
            "Epoch 9/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.8862 - val_loss: 3.3760\n",
            "Epoch 10/10\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0035 - val_accuracy: 0.8965 - val_loss: 3.2715\n",
            "Test Accuracy: 89.80%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▆▆▇▆▅▇█▆▅</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▁▄▁▂▄▁▆▄▇</td></tr><tr><td>epoch/val_accuracy</td><td>▆▃▇▆▆▆▆█▁█</td></tr><tr><td>epoch/val_loss</td><td>▁▅▂▇▃▂▄▆█▇</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.99924</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00383</td></tr><tr><td>epoch/val_accuracy</td><td>0.89647</td></tr><tr><td>epoch/val_loss</td><td>3.27149</td></tr><tr><td>test_accuracy</td><td>0.89796</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">chocolate-sweep-6</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ir4nddyu' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/ir4nddyu</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241220_001842-ir4nddyu/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aa0qm81q with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_002300-aa0qm81q</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/aa0qm81q' target=\"_blank\">sparkling-sweep-7</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/aa0qm81q' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/aa0qm81q</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 0.8962 - val_loss: 3.1897\n",
            "Epoch 2/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.8951 - val_loss: 2.2973\n",
            "Epoch 3/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0032 - val_accuracy: 0.8959 - val_loss: 2.5833\n",
            "Epoch 4/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.8969 - val_loss: 4.0616\n",
            "Epoch 5/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.8959 - val_loss: 3.2356\n",
            "Epoch 6/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.8955 - val_loss: 3.1606\n",
            "Epoch 7/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.8955 - val_loss: 4.1476\n",
            "Epoch 8/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 0.8951 - val_loss: 5.1614\n",
            "Epoch 9/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0041 - val_accuracy: 0.8935 - val_loss: 2.9629\n",
            "Epoch 10/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.8897 - val_loss: 4.0677\n",
            "Epoch 11/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.8958 - val_loss: 2.7687\n",
            "Epoch 12/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.8945 - val_loss: 2.9010\n",
            "Epoch 13/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.8948 - val_loss: 3.8442\n",
            "Epoch 14/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.8926 - val_loss: 3.2520\n",
            "Epoch 15/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.8887 - val_loss: 3.7000\n",
            "Epoch 16/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.8964 - val_loss: 3.6869\n",
            "Epoch 17/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.8952 - val_loss: 3.6515\n",
            "Epoch 18/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.8934 - val_loss: 4.5038\n",
            "Epoch 19/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.8930 - val_loss: 4.1498\n",
            "Epoch 20/20\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.8948 - val_loss: 3.3199\n",
            "Test Accuracy: 89.72%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▆▃▅▆▃▁▅▆▂▆▄▆▂▆▇▄██▆▂</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▇▃▆▂▆▅▁▃█▂▅▅▃▅▃▄▁▂▄▇</td></tr><tr><td>epoch/val_accuracy</td><td>▇▆▇█▇▇▇▆▅▂▇▆▆▄▁█▇▅▅▆</td></tr><tr><td>epoch/val_loss</td><td>▃▁▂▅▃▃▆█▃▅▂▂▅▃▄▄▄▆▆▃</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.99924</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00408</td></tr><tr><td>epoch/val_accuracy</td><td>0.89478</td></tr><tr><td>epoch/val_loss</td><td>3.31987</td></tr><tr><td>test_accuracy</td><td>0.89717</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sparkling-sweep-7</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/aa0qm81q' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/aa0qm81q</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 40 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241220_002300-aa0qm81q/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p6wmo06u with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_003126-p6wmo06u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/p6wmo06u' target=\"_blank\">absurd-sweep-8</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/p6wmo06u' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/p6wmo06u</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.8954 - val_loss: 3.0976\n",
            "Epoch 2/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.9541e-05 - val_accuracy: 0.8959 - val_loss: 3.9153\n",
            "Epoch 3/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.4837e-05 - val_accuracy: 0.8963 - val_loss: 4.4543\n",
            "Epoch 4/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 7.5489e-04 - val_accuracy: 0.8947 - val_loss: 5.9717\n",
            "Epoch 5/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.8952 - val_loss: 4.5171\n",
            "Epoch 6/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 6.9647e-04 - val_accuracy: 0.8962 - val_loss: 4.7525\n",
            "Epoch 7/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.7031e-04 - val_accuracy: 0.8956 - val_loss: 5.8863\n",
            "Epoch 8/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.8959 - val_loss: 4.7515\n",
            "Epoch 9/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 5.8157e-04 - val_accuracy: 0.8945 - val_loss: 5.8977\n",
            "Epoch 10/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.8953 - val_loss: 4.6571\n",
            "Epoch 11/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 8.6852e-04 - val_accuracy: 0.8950 - val_loss: 4.4822\n",
            "Epoch 12/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.8941 - val_loss: 3.2369\n",
            "Epoch 13/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 2.4425e-04 - val_accuracy: 0.8945 - val_loss: 5.5463\n",
            "Epoch 14/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 9.5987e-04 - val_accuracy: 0.8951 - val_loss: 4.5629\n",
            "Epoch 15/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 7.9216e-04 - val_accuracy: 0.8951 - val_loss: 3.8625\n",
            "Epoch 16/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 3.3089e-04 - val_accuracy: 0.8961 - val_loss: 5.1021\n",
            "Epoch 17/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.8961 - val_loss: 4.8082\n",
            "Epoch 18/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 4.6315e-04 - val_accuracy: 0.8964 - val_loss: 5.8774\n",
            "Epoch 19/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.8955 - val_loss: 5.0800\n",
            "Epoch 20/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 2.4062e-04 - val_accuracy: 0.8965 - val_loss: 5.8235\n",
            "Test Accuracy: 89.78%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁██▃▄▅▆▂▅▅▄▅▇▅▃▅▅▄▃▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▆▁▁█▅▃▃▆▃▅▅▅▂▄▅▃▄▄▄▃</td></tr><tr><td>epoch/val_accuracy</td><td>▅▆▇▃▄▇▅▆▂▅▄▁▂▄▄▇▇█▅█</td></tr><tr><td>epoch/val_loss</td><td>▁▃▄█▄▅█▅█▅▄▁▇▅▃▆▅█▆█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.99989</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00063</td></tr><tr><td>epoch/val_accuracy</td><td>0.89649</td></tr><tr><td>epoch/val_loss</td><td>5.82353</td></tr><tr><td>test_accuracy</td><td>0.89776</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">absurd-sweep-8</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/p6wmo06u' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/p6wmo06u</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 40 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241220_003126-p6wmo06u/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x8kh8wg4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_003544-x8kh8wg4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/x8kh8wg4' target=\"_blank\">azure-sweep-9</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/x8kh8wg4' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/x8kh8wg4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 0.8968 - val_loss: 6.0950\n",
            "Epoch 2/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.8972 - val_loss: 3.5778\n",
            "Epoch 3/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.8932 - val_loss: 4.7904\n",
            "Epoch 4/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.8931 - val_loss: 4.0148\n",
            "Epoch 5/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 0.8919 - val_loss: 5.2537\n",
            "Epoch 6/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0032 - val_accuracy: 0.8960 - val_loss: 3.9741\n",
            "Epoch 7/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.8932 - val_loss: 6.9411\n",
            "Epoch 8/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0046 - val_accuracy: 0.8959 - val_loss: 4.8967\n",
            "Epoch 9/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.8941 - val_loss: 3.9671\n",
            "Epoch 10/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.8923 - val_loss: 4.2513\n",
            "Epoch 11/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.8945 - val_loss: 3.8417\n",
            "Epoch 12/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.8946 - val_loss: 4.5730\n",
            "Epoch 13/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.8948 - val_loss: 6.8721\n",
            "Epoch 14/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0057 - val_accuracy: 0.8952 - val_loss: 4.6925\n",
            "Epoch 15/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0037 - val_accuracy: 0.8958 - val_loss: 4.6410\n",
            "Epoch 16/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.8930 - val_loss: 4.5821\n",
            "Epoch 17/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.8962 - val_loss: 3.8022\n",
            "Epoch 18/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0028 - val_accuracy: 0.8949 - val_loss: 5.2398\n",
            "Epoch 19/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.8942 - val_loss: 4.7110\n",
            "Epoch 20/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0033 - val_accuracy: 0.8938 - val_loss: 4.5122\n",
            "Epoch 21/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0040 - val_accuracy: 0.8948 - val_loss: 4.4298\n",
            "Epoch 22/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0038 - val_accuracy: 0.8957 - val_loss: 5.5958\n",
            "Epoch 23/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.8943 - val_loss: 3.8116\n",
            "Epoch 24/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.8961 - val_loss: 3.3690\n",
            "Epoch 25/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0040 - val_accuracy: 0.8947 - val_loss: 4.5678\n",
            "Epoch 26/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0035 - val_accuracy: 0.8952 - val_loss: 4.2190\n",
            "Epoch 27/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.8945 - val_loss: 5.4219\n",
            "Epoch 28/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0034 - val_accuracy: 0.8931 - val_loss: 4.6024\n",
            "Epoch 29/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.8920 - val_loss: 3.7804\n",
            "Epoch 30/30\n",
            "\u001b[1m6750/6750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.8951 - val_loss: 5.2727\n",
            "Test Accuracy: 89.87%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▃▅▄▆▁▃▃▃▅▁▅▅▆▂▄▆▅▆▃▄▁▁▄▆▂▅▅▅▆█</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▆▃▂▂▆▄▃▄▃▄▁▂▂▆▄▄▂▄▇▅▄█▅▄▃▄▃▄▂▃</td></tr><tr><td>epoch/val_accuracy</td><td>██▃▃▁▆▃▆▄▂▅▅▅▅▆▂▇▅▄▄▅▆▄▇▅▅▄▃▁▅</td></tr><tr><td>epoch/val_loss</td><td>▆▁▄▂▅▂█▄▂▃▂▃█▄▃▃▂▅▄▃▃▅▂▁▃▃▅▃▂▅</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.9996</td></tr><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00329</td></tr><tr><td>epoch/val_accuracy</td><td>0.89514</td></tr><tr><td>epoch/val_loss</td><td>5.2727</td></tr><tr><td>test_accuracy</td><td>0.89867</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">azure-sweep-9</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/x8kh8wg4' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/x8kh8wg4</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 60 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241220_003544-x8kh8wg4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fus47gcv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeedForward_dim: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_004818-fus47gcv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/fus47gcv' target=\"_blank\">eager-sweep-10</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/fus47gcv' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/fus47gcv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.8947 - val_loss: 5.9955\n",
            "Epoch 2/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.8965 - val_loss: 5.1534\n",
            "Epoch 3/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.8948 - val_loss: 7.2689\n",
            "Epoch 4/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0024 - val_accuracy: 0.8898 - val_loss: 6.6403\n",
            "Epoch 5/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 6.8555e-04 - val_accuracy: 0.8955 - val_loss: 8.8216\n",
            "Epoch 6/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0024 - val_accuracy: 0.8944 - val_loss: 6.2289\n",
            "Epoch 7/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.8955 - val_loss: 5.7015\n",
            "Epoch 8/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.8948 - val_loss: 5.3797\n",
            "Epoch 9/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.8957 - val_loss: 6.3571\n",
            "Epoch 10/10\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.8949 - val_loss: 7.9542\n",
            "Test Accuracy: 89.60%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▄▂▅▃█▁▅▅▃▅</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▂█▅▇▁█▃▄▄▄</td></tr><tr><td>epoch/val_accuracy</td><td>▆█▆▁▇▆▇▆▇▆</td></tr><tr><td>epoch/val_loss</td><td>▃▁▅▄█▃▂▁▃▆</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.99973</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.0019</td></tr><tr><td>epoch/val_accuracy</td><td>0.89494</td></tr><tr><td>epoch/val_loss</td><td>7.95417</td></tr><tr><td>test_accuracy</td><td>0.896</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">eager-sweep-10</strong> at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/fus47gcv' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/fus47gcv</a><br> View project at: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241220_004818-fus47gcv/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project=\"transformer-sweep\")\n",
        "\n",
        "\n",
        "artifact = run.use_artifact('jubacochran-booking-com/transformer-sweep/run_bdcumq2v_model:v9', type='model')\n",
        "\n",
        "\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "print(f\"Downloaded Artifact Directory: {artifact_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "JKJgSH3cyK5e",
        "outputId": "894a958c-5d25-497e-e1f7-e8d3b2cce9d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'transformer-sweep' when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_005105-fus47gcv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/fus47gcv' target=\"_blank\">eager-sweep-10</a></strong> to <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/sweeps/ulyniuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/fus47gcv' target=\"_blank\">https://wandb.ai/jubacochran-booking-com/transformer-sweep/runs/fus47gcv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Artifact Directory: /content/artifacts/run_bdcumq2v_model:v9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model(\"/content/artifacts/run_bdcumq2v_model:v9/transformer_model_hyperparameter.keras\")"
      ],
      "metadata": {
        "id": "i0G32TUqzxQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, tokenizer, test_sentences):\n",
        "\n",
        "    test_tokens = tokenizer.tokenize(test_sentences)\n",
        "\n",
        "    # Use the model to predict sentiment\n",
        "    predictions = model.predict(test_tokens)\n",
        "    predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary classes (0 or 1)\n",
        "\n",
        "    for i, sentence in enumerate(test_sentences):\n",
        "        sentiment = \"Positive\" if predictions[i] == 1 else \"Negative\"\n",
        "        print(f\"Input: {sentence}\\nPredicted Sentiment: {sentiment}\\n\")\n"
      ],
      "metadata": {
        "id": "B8S8OeY_Wfts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_sentences = [\n",
        "    \"This product was amazing! Highly recommend it.\",\n",
        "    \"The movie was terrible and I hated it.\",\n",
        "    \"It was okay, not great but not bad either.\",\n",
        "    \"Absolutely loved it, would buy again!\",\n",
        "    \"Worst purchase I have ever made.\",\n",
        "    \"I am not sure if I like my purchase\",\n",
        "    \"The beginning of the story was really intriging. Later the characters in the novel didnt develop as much. It is was a short book.\",\n",
        "    \"happy with it...but\"\n",
        "]\n",
        "\n",
        "\n",
        "test_model(best_model, tokenizer, test_sentences)\n"
      ],
      "metadata": {
        "id": "bkTycTXlWfyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1360fff-c520-4fb6-911b-c9e6aa639408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Input: This product was amazing! Highly recommend it.\n",
            "Predicted Sentiment: Negative\n",
            "\n",
            "Input: The movie was terrible and I hated it.\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Input: It was okay, not great but not bad either.\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Input: Absolutely loved it, would buy again!\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Input: Worst purchase I have ever made.\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Input: I am not sure if I like my purchase\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Input: The beginning of the story was really intriging. Later the characters in the novel didnt develop as much. It is was a short book.\n",
            "Predicted Sentiment: Negative\n",
            "\n",
            "Input: happy with it...but\n",
            "Predicted Sentiment: Negative\n",
            "\n"
          ]
        }
      ]
    }
  ]
}